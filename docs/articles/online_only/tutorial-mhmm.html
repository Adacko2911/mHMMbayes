<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="mHMMbayes">
<title>Multilevel HMM tutorial • mHMMbayes</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Multilevel HMM tutorial">
<meta property="og:description" content="mHMMbayes">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-default navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">mHMMbayes</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../articles/online_only/get_started.html">Getting started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Functions and data</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../../articles/online_only/tutorial-mhmm.html">Tutorial mHMM</a>
    <a class="dropdown-item" href="../../articles/online_only/estimation-mhmm.html">Estimation of mHMM</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/emmekeaarts/mHMMbayes/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../../logo.png" class="logo" alt=""><h1>Multilevel HMM tutorial</h1>
                        <h4 data-toc-skip class="author">Emmeke Aarts</h4>
                        
      
      <small class="dont-index">Source: <a href="https://github.com/emmekeaarts/mHMMbayes/blob/HEAD/vignettes/online_only/tutorial-mhmm.Rmd" class="external-link"><code>vignettes/online_only/tutorial-mhmm.Rmd</code></a></small>
      <div class="d-none name"><code>tutorial-mhmm.Rmd</code></div>
    </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>With the  package mHMMbayes you can fit multilevel hidden Markov models. The multilevel hidden Markov model (HMM) is a generalization of the well-known hidden Markov model, tailored to accommodate (intense) longitudinal data of multiple individuals simultaneously. Using a multilevel framework, we allow for heterogeneity in the model parameters (transition probability matrix and conditional distribution), while estimating one overall HMM. The model has a great potential of application in many fields, such as the social sciences and medicine. The model can be fitted on multivariate data with a categorical distribution, and include individual level covariates (allowing for e.g., group comparisons on model parameters). Parameters are estimated using Bayesian estimation utilizing the forward-backward recursion within a hybrid Metropolis within Gibbs sampler. The package also includes a function to simulate data and a function to obtain the most likely hidden state sequence for each individual using the Viterbi algorithm</p>
    </div>
    
<p><br><br></p>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<div style="text-align: justify;">
<p>Hidden Markov models [HMMs; <span class="citation"><a href="#ref-Rabiner1989" role="doc-biblioref">Rabiner</a> (<a href="#ref-Rabiner1989" role="doc-biblioref">1989</a>)</span>] are a machine learning method that have been used in many different scientific fields to describe a sequence of observations for several decades. For example, translating a fragment of spoken words into text <span class="citation">(i.e., speech recognition, see e.g. <a href="#ref-Rabiner1989" role="doc-biblioref">Rabiner 1989</a>; <a href="#ref-woodland2002" role="doc-biblioref">Woodland and Povey 2002</a>)</span>, or the identification of the regions of DNA that encode genes <span class="citation">(i.e., gene tagging, see e.g., <a href="#ref-krogh1994" role="doc-biblioref">Krogh, Mian, and Haussler 1994</a>; <a href="#ref-henderson1997" role="doc-biblioref">Henderson, Salzberg, and Fasman 1997</a>; <a href="#ref-burge1998" role="doc-biblioref">Burge and Karlin 1998</a>)</span>. The development of this package is, however, motivated from the area of social sciences. Due to technological advancements, it becomes increasingly easy to collect long sequences of data on behavior. That is, we can monitor behavior as it unfolds in real time. An example here of is the interaction between a therapist and a patient, where different types of nonverbal communication are registered every second for a period of 15 minutes. When applying HMMs to such behavioral data, they can be used to extract latent behavioral states over time, and model the dynamics of behavior over time.<br>
A quite recent development in HMMs is the extension to multilevel HMMs <span class="citation">(see e.g., <a href="#ref-altman2007" role="doc-biblioref">Altman 2007</a>; <a href="#ref-shirley2010" role="doc-biblioref">Shirley et al. 2010</a>; <a href="#ref-rueda2013" role="doc-biblioref">Rueda, Rueda, and Diaz-Uriarte 2013</a>; <a href="#ref-zhang2014" role="doc-biblioref">Zhang and Berhane 2014</a>; <a href="#ref-deHaan2017" role="doc-biblioref">Haan-Rietdijk et al. 2017</a>)</span>. Using the multilevel framework, we can model several sequences (e.g., sequences of different persons) simultaneously, while accommodating the heterogeneity between persons. As a result, we can quantify the amount of variation between persons in their dynamics of behavior, easily perform group comparisons on the model parameters, and investigate how model parameters change as a result of a covariate. For example, are the dynamics between a patient and a therapist different for patients with a good therapeutic outcome and patients with a less favorable therapeutic outcome?<br>
With the package <code>mHMMbayes</code>, one can estimate these multilevel hidden Markov models. This tutorial starts out with a brief description of the HMM and the multilevel HMM. For a more elaborate and gentle introduction to HMMs, we refer to <span class="citation"><a href="#ref-zucchini2016" role="doc-biblioref">Zucchini, MacDonald, and Langrock</a> (<a href="#ref-zucchini2016" role="doc-biblioref">2016</a>)</span>. Next, we show how to use the package <code>mHMMbayes</code> through an extensive example, also touching on the issues of determining the number of hidden states and checking model convergence. Information on the used estimation methods and algorithms in the package is given in the vignette <a href="estimation-mhmm.html">Estimation of the multilevel hidden Markov model</a>.</p>
<div class="section level2">
<h2 id="hidden-markov-models">Hidden Markov models<a class="anchor" aria-label="anchor" href="#hidden-markov-models"></a>
</h2>
<p>Hidden Markov Models are used for data for which 1) we believe that the distribution generating the observation depends on the state of an underlying, hidden state, and 2) the hidden states follow a Markov process, i.e., the states over time are not independent of one another, but the current state depends on the previous state only (and not on earlier states) <span class="citation">(see e.g., <a href="#ref-Rabiner1989" role="doc-biblioref">Rabiner 1989</a>; <a href="#ref-ephraim2002" role="doc-biblioref">Ephraim and Merhav 2002</a>; <a href="#ref-cappe2005" role="doc-biblioref">Cappé 2005</a>; <a href="#ref-zucchini2016" role="doc-biblioref">Zucchini, MacDonald, and Langrock 2016</a>)</span>. The HMM is a discrete time model: for each point in time <span class="math inline">\(t\)</span>, we have one hidden state that generates one observed event for that time point <span class="math inline">\(t\)</span>.<br>
Hence, the probability of observing the current outcome <span class="math inline">\(O_t\)</span> is exclusively determined by the current latent state <span class="math inline">\(S_t\)</span>:</p>
<p><span class="math display">\[\begin{equation}
Pr(O_{t} \mid \ O_{t-1}, O_{t-2}, \ldots, O_{1}, \ S_{t}, S_{t-1}, \ldots, S_{1}) = Pr(O_{t} \mid S_{t}).
\end{equation}\]</span></p>
<p>The probability of observing <span class="math inline">\(O_t\)</span> given <span class="math inline">\(S_t\)</span> can have any distribution, e.g., discrete or continuous. In the current version of the package <code>mHMMbayes</code>, only the categorical emission distribution is implemented.<br>
The hidden states in the sequence take values from a countable finite set of states <span class="math inline">\(S_t = i, i \in \{1, 2, \ldots, m\}\)</span>, where <span class="math inline">\(m\)</span> denotes the number of distinct states, that form the Markov chain, with the Markov property:</p>
<p><span class="math display">\[\begin{equation}
Pr(S_{t+1} \mid \ S_{t}, S_{t-1}, \ldots, S_{1}) = Pr(S_{t+1} \mid S_{t}).
\end{equation}\]</span></p>
<p>That is, the probability of switching to the next state <span class="math inline">\(S_{t+1}\)</span> depends only on the current state <span class="math inline">\(S_t\)</span>. As the HMM is a discrete time model, the duration of a state is represented by the self-transition probabilities <span class="math inline">\(\gamma_{ii}\)</span>, where the probability of a certain time t spent in state <span class="math inline">\(S\)</span> is given by the geometric distribution: <span class="math inline">\(\gamma_{ii}^{t-1}(1-\gamma_{ii})\)</span>.<br>
The HMM includes three sets of parameters: the initial probabilities of the states <span class="math inline">\(\pi_i\)</span>, the matrix <span class="math inline">\(\mathbf{\Gamma}\)</span> including the transition probabilities <span class="math inline">\(\gamma_{ij}\)</span> between the states, and the state-dependent probability distribution of observing <span class="math inline">\(O_t\)</span> given <span class="math inline">\(S_t\)</span> with parameter set <span class="math inline">\(\boldsymbol{\theta}_i\)</span>. The initial probabilities <span class="math inline">\(\pi_i\)</span> denote the probability that the first state in the hidden state sequence, <span class="math inline">\(S_1\)</span>, is <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\pi_i = Pr(S_1 = i) \quad \text{with} \sum_i \pi_i = 1. 
\end{equation}\]</span></p>
<p>Often, the initial probabilities of the states <span class="math inline">\(\pi_i\)</span> are assumed to be the stationary distribution implied by the transition probability matrix <span class="math inline">\(\mathbf{\Gamma}\)</span>, that is, the long term steady-state probabilities obtained by <span class="math inline">\(\lim_{T \rightarrow \infty} \mathbf{\Gamma}^T\)</span>. The transition probability matrix <span class="math inline">\(\mathbf{\Gamma}\)</span> with transition probabilities <span class="math inline">\(\gamma_{ij}\)</span> denote the probability of switching from state <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> to state <span class="math inline">\(j\)</span> at time <span class="math inline">\(t+1\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\gamma_{ij} = Pr(S_{t+1} = j \mid S_{t} = i) \quad \text{with} \sum_j \gamma_{ij} = 1.
\end{equation}\]</span></p>
<p>That is, the transition probabilities <span class="math inline">\(\gamma_{ij}\)</span> in the HMM represent the probability to switch between hidden states rather than between observed acts, as in the MC and CTMC model. The state-dependent probability distribution denotes the probability of observing <span class="math inline">\(O_t\)</span> given <span class="math inline">\(S_t\)</span> with parameter set <span class="math inline">\(\boldsymbol{\theta}_i\)</span>. In case of the package, the state-dependent probability distribution is given by the categorical distribution, and the parameter set <span class="math inline">\(\boldsymbol{\theta}_i\)</span> is the set of state-dependent probabilities of observing categorical outcomes. That is,</p>
<p><span class="math display">\[\begin{equation}
Pr(O_t = o \mid S_t = i) \sim \text{Cat} (\boldsymbol{\theta}_i),
\end{equation}\]</span></p>
<p>for the observed outcomes <span class="math inline">\(o = 1, 2, \ldots, q\)</span> and where <span class="math inline">\(\boldsymbol{\theta}_i = (\theta_{i1}, \theta_{i2}, \ldots, \theta_{iq})\)</span> is a vector of probabilities for each state <span class="math inline">\(S = i, \ldots, m\)</span> with <span class="math inline">\(\sum \theta_i = 1\)</span>, i.e., within each state, the probabilities of all possible outcomes sum up to 1.<br>
We assume that all parameters in the HMM are independent of <span class="math inline">\(t\)</span>, i.e., we assume a time-homogeneous model. In the vignette <a href="estimation-mhmm.pdf">Estimation of the multilevel hidden Markov model</a> we discuss three methods (i.e., Maximum likelihood, Expectation Maximization or Baum-Welch algorithm, and Bayesian estimation) to estimate the parameters of an HMM. In the package <code>mHMMbayes</code>, we chose to use Bayesian estimation because of its flexibility, which we will require in the multilevel framework of the model.</p>
</div>
<div class="section level2">
<h2 id="multilevel-hidden-markov-models">Multilevel hidden Markov models<a class="anchor" aria-label="anchor" href="#multilevel-hidden-markov-models"></a>
</h2>
<p>Given data of multiple subjects, one may fit the HMM to the data of each subject separately, or fit one and the same HMM model to the data of all subject, under the strong (generally untenable) assumption that the subjects do not differ with respect to the parameters of the HMM. Fitting a different model to each behavioral sequence is not parsimonious, computationally intensive, and results in a large number of parameters estimates. Neither approach lends itself well for a formal comparison (e.g., comparing the parameters over experimental conditions). To facilitate the analysis of multiple subjects, the HMM is extended by putting it in a multilevel framework.<br>
In multilevel models, model parameters are specified that pertain to different levels in the data. For example, subject-specific model parameters describe the data collected within each subject, and group level parameters describe what is typically observed within the group of subjects, and the variation observed between subjects. In the implemented multilevel HMM, we allow each subject to have its own unique parameter values within the same HMM model (i.e., identical number and similar composition of the hidden states). Rather than estimating these subject-specific parameters individually, we assume that the parameters of the HMM are random, i.e., follow a given group level distribution. Within this multilevel structure, the mean and the variance of the group level distribution of a given parameter thus expresses the overall mean parameter value in a group of subjects and the parameter variability between the subjects in the group.<br>
Multilevel HMMs have received some attention in the literature. In a frequentist context, <span class="citation"><a href="#ref-altman2007" role="doc-biblioref">Altman</a> (<a href="#ref-altman2007" role="doc-biblioref">2007</a>)</span> presented a general framework for HMMs for multiple processes by defining a class of Mixed Hidden Markov Models (MHMMs). These models are however, computationally intensive and due to slow convergence only suited for modeling a limited number of random effects. The approach of Altman has been translated to the Bayesian framework, which proved much faster as the time to reach convergence is decreased <span class="citation"><a href="#ref-zhang2014" role="doc-biblioref">Zhang and Berhane</a> (<a href="#ref-zhang2014" role="doc-biblioref">2014</a>)</span>. In addition, the HMM in a Bayesian context is easier to adapt to a multilevel model, as the need for numerical integration is eliminated. Examples of the application of the multilevel HMM (within a Bayesian framework) are: <span class="citation"><a href="#ref-rueda2013" role="doc-biblioref">Rueda, Rueda, and Diaz-Uriarte</a> (<a href="#ref-rueda2013" role="doc-biblioref">2013</a>)</span> applied the model to the analysis of DNA copy number data, <span class="citation"><a href="#ref-zhang2014" role="doc-biblioref">Zhang and Berhane</a> (<a href="#ref-zhang2014" role="doc-biblioref">2014</a>)</span> to identify risk factors for asthma, <span class="citation"><a href="#ref-shirley2010" role="doc-biblioref">Shirley et al.</a> (<a href="#ref-shirley2010" role="doc-biblioref">2010</a>)</span> to clinical trial data of a treatment for alcoholism and <span class="citation"><a href="#ref-deHaan2017" role="doc-biblioref">Haan-Rietdijk et al.</a> (<a href="#ref-deHaan2017" role="doc-biblioref">2017</a>)</span> to longitudinal data sets in psychology.<br>
In the tutorial, we use the following notation for the parameters in the multilevel HMM. The subject specific parameters are supplemented with the prefix <span class="math inline">\(k\)</span>, denoting subject <span class="math inline">\(k \in \{1,2,\ldots,K\}\)</span>. Hence, in the multilevel (Bayesian) HMM, the subject specific parameters are: the subject-specific transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span> with transition probabilities <span class="math inline">\(\gamma_{k,ij}\)</span>, and the subject-specific emission distributions denoting subject-specific probabilities <span class="math inline">\(\boldsymbol{\theta}_{k,i}\)</span> of categorical outcomes within hidden state <span class="math inline">\(i\)</span>. The initial probabilities of the states <span class="math inline">\(\pi_{k,j}\)</span> are not estimated as <span class="math inline">\(\pi_{k}\)</span> is assumed to be the stationary distribution of <span class="math inline">\(\boldsymbol{\Gamma}_k\)</span>. The group level parameters are: the group level state transition probability matrix <span class="math inline">\(\boldsymbol{\Gamma}\)</span> with transition probabilities <span class="math inline">\(\gamma_{ij}\)</span>, and the group level state-dependent probabilities <span class="math inline">\(\boldsymbol{\theta}_{i}\)</span>. We fit the model using Bayesian estimation (i.e., a hybrid Metropolis Gibbs sampler that utilizes the forward-backward recursion to sample the hidden state sequence of each subject, see the vignette <a href="estimation-mhmm.pdf">Estimation of the multilevel hidden Markov model</a>).</p>
</div>
<div class="section level2">
<h2 id="using-the-package-mhmmbayes">Using the package mHMMbayes<a class="anchor" aria-label="anchor" href="#using-the-package-mhmmbayes"></a>
</h2>
<p>We illustrate using the package using the embedded example data <code>nonverbal</code>. The data contains the nonverbal communication of 10 patient-therapist couples, recorded for 15 minutes at a frequency of 1 observation per second (= 900 observations per couple). The following variables are contained in the dataset:</p>
<ul>
<li>
<code>id</code>: id variable of patient - therapist couple to distinguish which observation belongs to which couple.</li>
<li>
<code>p_verbalizing</code>: verbalizing behavior of the patient, consisting of 1 = not verbalizing, 2 = verbalizing, 3 = back channeling.</li>
<li>
<code>p_looking</code>: looking behavior of the patient, consisting of 1 = not looking at therapist, 2 = looking at therapist.</li>
<li>
<code>t_verbalizing</code>: verbalizing behavior of the therapist, consisting of 1 = not verbalizing, 2 = verbalizing, 3 = back channeling.</li>
<li>
<code>t_looking</code>: looking behavior of the therapist, consisting of 1 = not looking at patient, 2 = looking at patient. The top 6 rows of the dataset are provided below.</li>
</ul>
<p>When we plot the data of the first 5 minutes (= the first 300 observations) of the first couple, we get the following:</p>
<pre><code><span><span class="co">#&gt; Warning: package 'RColorBrewer' was built under R version 4.1.3</span></span></code></pre>
<p><img src="tutorial-mhmm_files/figure-html/plot%20observed%20data-1.png" width="691.2"></p>
<p>We can, for example, observe that both the patient and the therapist are mainly looking at each other during the observed 5 minutes. During the first minute, the patient is primarily speaking. During the second minute, the therapists starts, after which the patient takes over while the therapist is back channeling.</p>
<div class="section level3">
<h3 id="a-simple-model">A simple model<a class="anchor" aria-label="anchor" href="#a-simple-model"></a>
</h3>
<p>To fit a simple 2 state multilevel model with the function <code>mHMM</code>, one first has to specify some general model properties and starting values:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/emmekeaarts/mHMMbayes" class="external-link">mHMMbayes</a></span><span class="op">)</span></span>
<span><span class="co"># specifying general model properties:</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">n_dep</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">q_emiss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># specifying starting values</span></span>
<span><span class="va">start_TM</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">.8</span>, <span class="va">m</span><span class="op">)</span></span>
<span><span class="va">start_TM</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/lower.tri.html" class="external-link">lower.tri</a></span><span class="op">(</span><span class="va">start_TM</span><span class="op">)</span> <span class="op">|</span> <span class="fu"><a href="https://rdrr.io/r/base/lower.tri.html" class="external-link">upper.tri</a></span><span class="op">(</span><span class="va">start_TM</span><span class="op">)</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">.2</span></span>
<span><span class="va">start_EM</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">0.90</span>, <span class="fl">0.05</span>, </span>
<span>                          <span class="fl">0.90</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                         nrow <span class="op">=</span> <span class="va">m</span>, ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>, <span class="co"># vocalizing patient</span></span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span>, </span>
<span>                           <span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>, nrow <span class="op">=</span> <span class="va">m</span>,</span>
<span>                         ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>, <span class="co"># looking patient</span></span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.90</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, </span>
<span>                           <span class="fl">0.05</span>, <span class="fl">0.90</span>, <span class="fl">0.05</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                         nrow <span class="op">=</span> <span class="va">m</span>, ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span>, <span class="co"># vocalizing therapist</span></span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span>, </span>
<span>                           <span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>, nrow <span class="op">=</span> <span class="va">m</span>,</span>
<span>                         ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="co"># looking therapist</span></span></code></pre></div>
<p>The first line of code loads the <code>mHMMbayes</code> package and the <code>nonverbal</code> data. Next we specify the general model properties: the number of states used is set by <code>m &lt;- 2</code>, the number of dependent variables in the dataset used to infer the hidden states is specified by <code>n_dep &lt;- 4</code>, and the number of categorical outcomes for each of the dependent variables is specified by <code>q_emiss &lt;- c(3, 2, 3, 2)</code>.</p>
<div class="section level4">
<h4 id="starting-values">Starting values<a class="anchor" aria-label="anchor" href="#starting-values"></a>
</h4>
<p>The subsequent lines of code specify starting values for both the transition probability matrix and the emission distribution(s), which are given to the model in the argument <code>start_val</code> (see next piece of code). These starting values are used for the first run of the forward backward algorithm. Although the hidden states cannot be observed, one often has an idea for probable compositions of the states. In the example, we expect that there is a state in which the patient mostly speaks, and the therapist is silent, and a state during which the patient is silent and the therapists speaks. In addition, we expect that during both states, the therapist and the patient will be mainly looking at each other instead of looking away. One usually also has some (vague) idea on likely and unlikely switches between states, and the size of self-transition probabilities. In the example, we think a state will usually last quite some seconds, and thus expect a rather high self-transition probability. All these ideas can be used to construct a set of sensible starting values. Using sensible starting values increases convergence speed, and often prevents a problem called ‘label switching.’ Hence, using random or uniform starting values is not recommended, and a default option to do so is not included in the package. Note that it is strongly advised to check model convergence and label switching. That is, one should check if the algorithm reaches the same solution when a set of different (but often conceptually similar) starting values are used, and if label switching is not a problem. See the section <em>Checking model convergence and label switching</em> for an example. See the vignette <a href="estimation-mhmm.pdf">Estimation of the multilevel hidden Markov model</a>) for more information on the forward backward algorithm and on the problem of label switching.</p>
</div>
<div class="section level4">
<h4 id="prior-distributions">Prior distributions<a class="anchor" aria-label="anchor" href="#prior-distributions"></a>
</h4>
<p>As the estimation proceeds within a Bayesian context, a (hyper-)prior distribution has to be defined for the group level parameters, i.e., the group level emission and transition probabilities. Default, non-informative priors are used unless specified otherwise by the user. Below, we present some information on this. For a more elaborate explanation on the used (hyper-)prior distributions and their parameters, see the vignette <a href="estimation-mhmm.pdf">Estimation of the multilevel hidden Markov model</a>.<br>
First of all, note that the prior distributions on the emission distribution and transition probabilities are not on the probabilities directly, but on the intercepts (and regression coefficients given that covariates are used) of the Multinomial regression model used to accommodate the multilevel framework of the data. Second, parameters do not each have their own independent prior distribution. As each row of the emission distribution matrix and transition probability matrix sum to one, the individual parameters of these rows are connected. Hence, each row is seen as a set of parameters which are estimated jointly, and each set of parameters has a multivariate prior distribution.<br>
The sets of intercepts of the Multinomial regression model have a multivariate normal distribution. The (hyper-) prior for these intercepts thus consists of a prior distribution on the vector of means, and a prior distribution on the covariance matrix. The hyper-prior for the mean intercepts is a multivariate Normal distribution, with, as default, a vector of means equal to 0, and a parameter <span class="math inline">\(K_0\)</span> with which the covariance matrix is multiplied. Here, <span class="math inline">\(K_0\)</span> denotes the number of observations (i.e., the number of hypothetical prior subjects) on which the prior mean vector of zero’s is based. By default, <span class="math inline">\(K_0\)</span> is set to 1. The hyper-prior for the covariance matrix between the set of (state specific) intercepts has an Inverse Wishart distribution, for which the variance in the default setting equals 3 + <span class="math inline">\(m\)</span> - 1 for the transition probabilities and 3 + <span class="math inline">\(q\)</span> - 1 for the emission probabilities, and the covariance equals 0. The degrees of freedom of the Inverse Wishart distribution is set to 3 + <span class="math inline">\(m\)</span> - 1 for the transition probabilities and 3 + <span class="math inline">\(q\)</span> - 1 for the emission probabilities.<br>
To specify user specific prior distributions, one uses the input option <code>emiss_hyp_prior</code> for the emission distribution and <code>gamma_hyp_prior</code> for the transition probabilities in the function <code>mHMM</code>. These input arguments take an object from the class <code>mHMM_prior_emiss</code> and <code>mHMM_prior_gamma</code> created by the functions <code>prior_emiss_cat</code> and <code>prior_gamma</code>, respectively. Both objects are a list, containing the following key elements:</p>
<ul>
<li>
<code>mu0</code>, a lists containing the hypothesized hyper-prior mean values of the intercepts of the Multinomial logit model.</li>
<li>
<code>K0</code>, the number of hypothetical prior subjects on which the set of hyper-prior mean intercepts specified in <code>mu0</code> are based.</li>
<li>
<code>nu</code>, degrees of freedom of the hyper-prior Inverse Wishart distribution on the covariance of the Multinomial logit intercepts.</li>
<li>
<code>V</code>, the variance-covariance of the hyper-prior Inverse Wishart distribution on the covariance of the Multinomial logit intercepts.</li>
</ul>
<p>Note that <code>K0</code>, <code>nu</code> and <code>V</code> are assumed equal over the states. The mean values of the intercepts (and regression coefficients of the covariates) denoted by <code>mu0</code> are allowed to vary over the states. All elements in the list either have the prefix <code>gamma_</code> or <code>emiss_</code>, depending on which list they belong to. When specifying prior distributions, note that the first element of each row in the probability domain does not have an intercept, as it serves as baseline category in the Multinomial logit regression model. This means, for example, that if we would specify a model with 3 states, <code>mu0</code> is a vector with 2 elements, <code>K0</code> and <code>nu</code> contain 1 element and <code>V</code> is a 2 by 2 matrix.</p>
</div>
<div class="section level4">
<h4 id="fitting-the-model">Fitting the model<a class="anchor" aria-label="anchor" href="#fitting-the-model"></a>
</h4>
<p>The multilevel HMM is fitted using the function <code>mHMM</code>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Run a model without covariate(s) and default priors:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">14532</span><span class="op">)</span></span>
<span><span class="va">out_2st</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/mHMM.html">mHMM</a></span><span class="op">(</span>s_data <span class="op">=</span> <span class="va">nonverbal</span>, </span>
<span>                    gen <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>m <span class="op">=</span> <span class="va">m</span>, n_dep <span class="op">=</span> <span class="va">n_dep</span>, q_emiss <span class="op">=</span> <span class="va">q_emiss</span><span class="op">)</span>, </span>
<span>                    start_val <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">start_TM</span><span class="op">)</span>, <span class="va">start_EM</span><span class="op">)</span>,</span>
<span>                    mcmc <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>J <span class="op">=</span> <span class="fl">1000</span>, burn_in <span class="op">=</span> <span class="fl">200</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The call to <code>mHMM</code> specifies the model with several arguments. The <code>s_data</code> argument specifies the input data used to infer the hidden states over time. The <code>gen</code> and <code>start_val</code> argument specify the general model properties and the starting values, as discussed above. The arguments needed for the MCMC algorithm are given in <code>mcmc</code>: <code>J</code> specifies the number of iterations used by the hybrid metropolis within Gibbs algorithm and <code>burn_in</code> specifies the number of iterations to discard when obtaining the model parameter summary statistics. The function <code>mHMM</code> returns an object of class <code>mHMM</code>, which has <code>print</code> and <code>summary</code> methods to see the results. The <code>print</code> method provides basic information on the model fitted. That is, the number of subjects in the dataset analyzed, the number of iterations and burn-in period, the average log likelihood over all subjects and model fit indices AIC, the number of states specified, and the number of dependent variables the states are based on:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">out_2st</span></span>
<span><span class="co">#&gt; Number of subjects: 10 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1000 iterations used in the MCMC algorithm with a burn in of 200 </span></span>
<span><span class="co">#&gt; Average Log likelihood over all subjects: -1624.389 </span></span>
<span><span class="co">#&gt; Average AIC over all subjects: 3276.777 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of states used: 2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of dependent variables used: 4</span></span></code></pre></div>
<p>The <code>summary</code> method provides information on the estimated parameters. That is, the point estimates of the posterior distribution for the transition probability matrix and the emission distribution of each of the dependent variables at the group level:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">out_2st</span><span class="op">)</span></span>
<span><span class="co">#&gt; State transition probability matrix </span></span>
<span><span class="co">#&gt;  (at the group level): </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.929      0.071</span></span>
<span><span class="co">#&gt; From state 2      0.074      0.926</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Emission distribution for each of the dependent variables </span></span>
<span><span class="co">#&gt;  (at the group level): </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; $p_vocalizing</span></span>
<span><span class="co">#&gt;         Category 1 Category 2 Category 3</span></span>
<span><span class="co">#&gt; State 1      0.018      0.957      0.024</span></span>
<span><span class="co">#&gt; State 2      0.795      0.052      0.153</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $p_looking</span></span>
<span><span class="co">#&gt;         Category 1 Category 2</span></span>
<span><span class="co">#&gt; State 1      0.248      0.752</span></span>
<span><span class="co">#&gt; State 2      0.096      0.904</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $t_vocalizing</span></span>
<span><span class="co">#&gt;         Category 1 Category 2 Category 3</span></span>
<span><span class="co">#&gt; State 1      0.806      0.075      0.119</span></span>
<span><span class="co">#&gt; State 2      0.034      0.945      0.020</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $t_looking</span></span>
<span><span class="co">#&gt;         Category 1 Category 2</span></span>
<span><span class="co">#&gt; State 1      0.047      0.953</span></span>
<span><span class="co">#&gt; State 2      0.277      0.723</span></span></code></pre></div>
<p>The resulting model indicates 2 well separated states: one in which the patient is speaking and one in which the therapist is speaking. Looking behavior is quite similar for both the patient and the therapist in the 2 states. Information on the estimated parameters can also be obtained using the function <code>obtain_gamma</code> and <code>obtain_emiss</code>. These functions allow the user not only to inspect the estimated parameters at the group level, but for each subject individually as well, by specifying the input variable <code>level = "subject"</code>:<br></p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># When not specified, level defaults to "group"</span></span>
<span><span class="va">gamma_pop</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/obtain_gamma.html">obtain_gamma</a></span><span class="op">(</span><span class="va">out_2st</span><span class="op">)</span></span>
<span><span class="va">gamma_pop</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.929      0.071</span></span>
<span><span class="co">#&gt; From state 2      0.074      0.926</span></span>
<span></span>
<span><span class="co"># To obtain the subject specific parameter estimates:</span></span>
<span><span class="va">gamma_subj</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/obtain_gamma.html">obtain_gamma</a></span><span class="op">(</span><span class="va">out_2st</span>, level <span class="op">=</span> <span class="st">"subject"</span><span class="op">)</span></span>
<span><span class="va">gamma_subj</span></span>
<span><span class="co">#&gt; $`Subject 1`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.942      0.058</span></span>
<span><span class="co">#&gt; From state 2      0.048      0.952</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 2`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.936      0.064</span></span>
<span><span class="co">#&gt; From state 2      0.060      0.940</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 3`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.969      0.031</span></span>
<span><span class="co">#&gt; From state 2      0.054      0.946</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 4`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.934      0.066</span></span>
<span><span class="co">#&gt; From state 2      0.046      0.954</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 5`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.942      0.058</span></span>
<span><span class="co">#&gt; From state 2      0.058      0.942</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 6`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.942      0.058</span></span>
<span><span class="co">#&gt; From state 2      0.087      0.913</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 7`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.929      0.071</span></span>
<span><span class="co">#&gt; From state 2      0.043      0.958</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 8`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1       0.93      0.070</span></span>
<span><span class="co">#&gt; From state 2       0.08      0.919</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 9`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.948      0.052</span></span>
<span><span class="co">#&gt; From state 2      0.058      0.942</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Subject 10`</span></span>
<span><span class="co">#&gt;              To state 1 To state 2</span></span>
<span><span class="co">#&gt; From state 1      0.960      0.040</span></span>
<span><span class="co">#&gt; From state 2      0.068      0.932</span></span></code></pre></div>
<p>An additional option that the functions <code>obtain_gamma</code> and <code>obtain_emiss</code> offer is changing the burn-in period used for obtaining the summary statistics, using the input variable <code>burn_in</code>.</p>
</div>
</div>
<div class="section level3">
<h3 id="graphically-displaying-outcomes">Graphically displaying outcomes<a class="anchor" aria-label="anchor" href="#graphically-displaying-outcomes"></a>
</h3>
<p>The package includes several plot functions to display the fitted model and its parameters. First, one can plot the posterior densities of a fitted model, for both the transition probability matrix gamma and for the emission distribution probabilities. The posterior densities are plotted for the group level and the subject level simultaneously. For example, for the emission distribution for the variable <code>p_vocalizing</code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">RColorBrewer</span><span class="op">)</span></span>
<span><span class="va">Voc_col</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html" class="external-link">brewer.pal</a></span><span class="op">(</span><span class="fl">3</span>,<span class="st">"PuBuGn"</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">3</span>,<span class="fl">2</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">Voc_lab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Not Speaking"</span>, <span class="st">"Speaking"</span>, <span class="st">"Back channeling"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">out_2st</span>, component <span class="op">=</span> <span class="st">"emiss"</span>, dep <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="va">Voc_col</span>, </span>
<span>     dep_lab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Patient vocalizing"</span><span class="op">)</span>, cat_lab <span class="op">=</span> <span class="va">Voc_lab</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial-mhmm_files/figure-html/show%20plot%20posterior%20densities-1.png" width="691.2"> Here, <code>component</code> specifies whether we want to visualize the posterior densities for the transition probability matrix gamma (<code>component = "gamma"</code>) or for the emission distribution probabilities (<code>component = "emiss"</code>), when using <code>component = "emiss"</code> the input variable <code>dep</code> specifies which dependent variable we want to inspect (as the variable <code>p_vocolizing</code> is the first variable in the set, we set <code>dep = 1</code>), <code>col</code> specifies the colors to be used when plotting the lines, <code>dep_lab</code> denotes the label of the dependent variable we are plotting, and <code>cat_lab</code> denotes the labels of the categorical outcomes in the dependent variable. In the plot, the solid line visualizes the posterior density at the group level, while each of the dotted lines visualizes the posterior density of one subject.<br>
Second, one can plot the transition probabilities obtained with the function <code>obtain_gamma</code> with a riverplot:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Transition probabilities at the group level and for subject number 1, respectively:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">gamma_pop</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html" class="external-link">brewer.pal</a></span><span class="op">(</span><span class="fl">3</span>,<span class="st">"PiYG"</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">2</span><span class="op">]</span>, each <span class="op">=</span> <span class="va">m</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">gamma_subj</span>, subj_nr <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html" class="external-link">brewer.pal</a></span><span class="op">(</span><span class="fl">3</span>,<span class="st">"PiYG"</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">2</span><span class="op">]</span>, each <span class="op">=</span> <span class="va">m</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial-mhmm_files/figure-html/show%20plot%20transition%20prob-1.png" width="700"><img src="tutorial-mhmm_files/figure-html/show%20plot%20transition%20prob-2.png" width="700"></p>
<p>Note that graphically displaying the transition probabilities becomes more informative as the number of states increase.<br></p>
</div>
<div class="section level3">
<h3 id="determining-the-number-of-hidden-states">Determining the number of hidden states<a class="anchor" aria-label="anchor" href="#determining-the-number-of-hidden-states"></a>
</h3>
<p>The first step in developing a HMM is to determine the number of states <span class="math inline">\(m\)</span> that best describes the observed data, and is a model selection problem. When modelling, for example, behavior, the task is to define the states by clusters of observed behavioral outcomes that provide a reasonable, theoretically interpretable, description of the data. We suggest using a combination of the Akaike Information Criterion (AIC) and the theoretical interpretability of the estimated states to choose between models<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;Note that the likelihood ratio test, commonly used to compare nested models, cannot be used in case of the HMM (i.e., the difference in the log-likelihoods between models is not &lt;span class="math inline"&gt;\(\chi^2\)&lt;/span&gt; distributed &lt;span class="citation"&gt;&lt;a href="#ref-ryden2008" role="doc-biblioref"&gt;Rydén&lt;/a&gt; (&lt;a href="#ref-ryden2008" role="doc-biblioref"&gt;2008&lt;/a&gt;)&lt;/span&gt;).&lt;/p&gt;'><sup>1</sup></a>. In the example dataset, the 2, 3 and 4 state model result in an AIC of 3279, 3087, and 2959, respectively. According to model fit indices, the 4 state model is clearly the best model<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;We note, however, that the AIC approximates the posterior distribution of the parameters by a Gaussian distribution, which might not be appropriate for models including parameters on the boundary of the parameter space (e.g., close to 0 or 1 in case of probability estimates), or for small data sets, as exemplified by &lt;span class="citation"&gt;&lt;a href="#ref-scott2002" role="doc-biblioref"&gt;Scott&lt;/a&gt; (&lt;a href="#ref-scott2002" role="doc-biblioref"&gt;2002&lt;/a&gt;)&lt;/span&gt;. Model selection is therefore not a straightforward procedure in the context of HMM, and the choices remain subjective.&lt;/p&gt;'><sup>2</sup></a>. Let’s inspect the composition of the states for the 4 state model, and the transition probabilities:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">out_4st</span><span class="op">)</span></span>
<span><span class="co">#&gt; State transition probability matrix </span></span>
<span><span class="co">#&gt;  (at the group level): </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt;              To state 1 To state 2 To state 3 To state 4</span></span>
<span><span class="co">#&gt; From state 1      0.910      0.031      0.040      0.019</span></span>
<span><span class="co">#&gt; From state 2      0.044      0.815      0.056      0.084</span></span>
<span><span class="co">#&gt; From state 3      0.183      0.097      0.666      0.054</span></span>
<span><span class="co">#&gt; From state 4      0.024      0.220      0.019      0.738</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Emission distribution for each of the dependent variables </span></span>
<span><span class="co">#&gt;  (at the group level): </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; $p_vocalizing</span></span>
<span><span class="co">#&gt;         Category 1 Category 2 Category 3</span></span>
<span><span class="co">#&gt; State 1      0.011      0.976      0.013</span></span>
<span><span class="co">#&gt; State 2      0.729      0.046      0.225</span></span>
<span><span class="co">#&gt; State 3      0.184      0.665      0.150</span></span>
<span><span class="co">#&gt; State 4      0.876      0.065      0.059</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $p_looking</span></span>
<span><span class="co">#&gt;         Category 1 Category 2</span></span>
<span><span class="co">#&gt; State 1      0.237      0.763</span></span>
<span><span class="co">#&gt; State 2      0.061      0.939</span></span>
<span><span class="co">#&gt; State 3      0.439      0.561</span></span>
<span><span class="co">#&gt; State 4      0.094      0.906</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $t_vocalizing</span></span>
<span><span class="co">#&gt;         Category 1 Category 2 Category 3</span></span>
<span><span class="co">#&gt; State 1      0.889      0.013      0.097</span></span>
<span><span class="co">#&gt; State 2      0.019      0.971      0.011</span></span>
<span><span class="co">#&gt; State 3      0.332      0.593      0.074</span></span>
<span><span class="co">#&gt; State 4      0.087      0.845      0.068</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $t_looking</span></span>
<span><span class="co">#&gt;         Category 1 Category 2</span></span>
<span><span class="co">#&gt; State 1      0.030      0.970</span></span>
<span><span class="co">#&gt; State 2      0.045      0.955</span></span>
<span><span class="co">#&gt; State 3      0.074      0.926</span></span>
<span><span class="co">#&gt; State 4      0.949      0.051</span></span>
<span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu"><a href="../../reference/obtain_gamma.html">obtain_gamma</a></span><span class="op">(</span><span class="va">out_4st</span><span class="op">)</span>, cex <span class="op">=</span> <span class="fl">.5</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html" class="external-link">brewer.pal</a></span><span class="op">(</span><span class="fl">5</span>,<span class="st">"PiYG"</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">3</span><span class="op">]</span>, each <span class="op">=</span> <span class="va">m</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial-mhmm_files/figure-html/show%204%20state%20model-1.png" width="480"></p>
<p>We can see that we have a state in which the patient speaks and the therapist is silent (state 1), a state in which the patient is silent and the therapist speaks (state 2), a state in which both the patient and therapist speak (state 3) and a state in which the therapist speaks but does not look at the patient (in contrast to the looking behavior in all other states), and the patient is silent. In addition, all states are quite stable as the probability of remaining in the same state is above .6 for all states.</p>
</div>
<div class="section level3">
<h3 id="determining-the-most-likely-state-sequence">Determining the most likely state sequence<a class="anchor" aria-label="anchor" href="#determining-the-most-likely-state-sequence"></a>
</h3>
<p>Given a well-fitting HMM, it may be of interest to determine the actual <em>sequence</em>, or order of succession, of hidden states that has most likely given rise to the sequence of outcomes as observed in a subject. One can either use local decoding, in which the probabilities of the hidden state sequence are obtained simultaneously with the model parameters estimates, or the well-known Viterbi algorithm <span class="citation">(<a href="#ref-viterbi1967" role="doc-biblioref">Viterbi 1967</a>; <a href="#ref-forney1973" role="doc-biblioref">Forney Jr 1973</a>)</span>. In local decoding, the most likely state is determined separately at each time point <span class="math inline">\(t\)</span>, in contrast to the Viterbi algorithm in which one determines the joint probability of the complete sequence of observations <span class="math inline">\(O_{1:T}\)</span> and the complete sequence of hidden states <span class="math inline">\(S_{1:T}\)</span>.<br>
In the package, local decoding can be achieved by saving the sampled hidden state sequence at each iteration of the Gibbs sampler, by setting the input variable <code>return_path = TRUE</code> for the function <code>mHMM</code>. This will result in very large output files, however. Global decoding can be performed by using the function <code>vit_mHMM</code>:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">state_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/vit_mHMM.html">vit_mHMM</a></span><span class="op">(</span><span class="va">out_2st</span>, s_data <span class="op">=</span> <span class="va">nonverbal</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">state_seq</span><span class="op">)</span></span>
<span><span class="co">#&gt;      Subj_1 Subj_2 Subj_3 Subj_4 Subj_5 Subj_6 Subj_7 Subj_8 Subj_9 Subj_10</span></span>
<span><span class="co">#&gt; [1,]      1      2      2      2      1      2      1      1      1       1</span></span>
<span><span class="co">#&gt; [2,]      1      2      2      2      1      2      1      1      1       1</span></span>
<span><span class="co">#&gt; [3,]      1      2      2      2      2      2      1      1      1       1</span></span>
<span><span class="co">#&gt; [4,]      1      2      2      2      2      2      1      1      1       1</span></span>
<span><span class="co">#&gt; [5,]      1      2      2      2      2      2      2      1      1       1</span></span>
<span><span class="co">#&gt; [6,]      1      2      2      2      2      1      2      1      1       1</span></span></code></pre></div>
<p>The function returns the hidden state sequence for each subject in a matrix, where each row represents a point in time and each column represents a subject. We can inspect the obtained hidden state sequence by for example plotting it together with the observed data. Below, the first 5 minutes of the first couple is plotted again, with the addition of the estimated state sequence:</p>
<p><img src="tutorial-mhmm_files/figure-html/plotting%20observed%20data%20plus%20inferred%20states-1.png" width="691.2"></p>
</div>
<div class="section level3">
<h3 id="checking-model-convergence-and-label-switching">Checking model convergence and label switching<a class="anchor" aria-label="anchor" href="#checking-model-convergence-and-label-switching"></a>
</h3>
<p>When using Bayesian estimation procedures, it is strongly advised to check model convergence and label switching. That is, one should check if the algorithm reaches the same solution when a set of different (but often conceptually similar) starting values are used, and if label switching is not a problem. With label switching, the label (i.e., which state represents what) ordering of the states switches over the iterations of the estimation algorithm. For example, what started out as state 1, now becomes state 2. One can check model convergence and label switching visually by inspecting the trace plots of parameters of a set of identical models that used varying starting values. Trace plots are plots of the sampled parameter values over the iterations. First, we fit the model with 2 states again, but with different starting values:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># specifying general model properties</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span><span class="fl">2</span></span>
<span><span class="va">n_dep</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">q_emiss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># specifying different starting values</span></span>
<span><span class="va">start_TM</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">.8</span>, <span class="va">m</span><span class="op">)</span></span>
<span><span class="va">start_TM</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/lower.tri.html" class="external-link">lower.tri</a></span><span class="op">(</span><span class="va">start_TM</span><span class="op">)</span> <span class="op">|</span> <span class="fu"><a href="https://rdrr.io/r/base/lower.tri.html" class="external-link">upper.tri</a></span><span class="op">(</span><span class="va">start_TM</span><span class="op">)</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">.2</span></span>
<span><span class="va">start_EM_b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.6</span>, <span class="fl">0.2</span>,</span>
<span>                            <span class="fl">0.6</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                        nrow <span class="op">=</span> <span class="va">m</span>, ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>, <span class="co"># vocalizing patient</span></span>
<span>                 <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.4</span>, <span class="fl">0.6</span>,</span>
<span>                          <span class="fl">0.4</span>, <span class="fl">0.6</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>, nrow <span class="op">=</span> <span class="va">m</span>,</span>
<span>                        ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>, <span class="co"># looking patient</span></span>
<span>                 <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>,</span>
<span>                          <span class="fl">0.2</span>, <span class="fl">0.6</span>, <span class="fl">0.2</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                        nrow <span class="op">=</span> <span class="va">m</span>, ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span>, <span class="co"># vocalizing therapist</span></span>
<span>                 <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.4</span>, <span class="fl">0.6</span>,</span>
<span>                          <span class="fl">0.4</span>, <span class="fl">0.6</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>, nrow <span class="op">=</span> <span class="va">m</span>,</span>
<span>                        ncol <span class="op">=</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="co"># looking therapist</span></span>
<span></span>
<span><span class="co"># Run a model identical to out_2st, but with different starting values:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">9843</span><span class="op">)</span></span>
<span><span class="va">out_2st_b</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/mHMM.html">mHMM</a></span><span class="op">(</span>s_data <span class="op">=</span> <span class="va">nonverbal</span>, </span>
<span>                      gen <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>m <span class="op">=</span> <span class="va">m</span>, n_dep <span class="op">=</span> <span class="va">n_dep</span>, q_emiss <span class="op">=</span> <span class="va">q_emiss</span><span class="op">)</span>, </span>
<span>                      start_val <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">start_TM</span><span class="op">)</span>, <span class="va">start_EM</span><span class="op">)</span>,</span>
<span>                      mcmc <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>J <span class="op">=</span> <span class="fl">1000</span>, burn_in <span class="op">=</span> <span class="fl">200</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The group level parameter estimates of the emission probabilities and the transition probability matrix at each iteration of the estimation algorithm are stored in the objects <code>emiss_prob_bar</code> and <code>gamma_prob_bar</code>, respectively. The subject level parameter estimates are stored in the object <code>PD_subj</code>, where PD is an abbreviation for posterior density. If we, for example, want to inspect the trace plots for the emission probabilities for looking behavior of the patient at the group level, we use the following code:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">m</span>,<span class="va">q_emiss</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">m</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">q</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">q_emiss</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">{</span></span>
<span>     <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span>, y <span class="op">=</span> <span class="va">out_2st</span><span class="op">$</span><span class="va">emiss_prob_bar</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">[</span>,<span class="op">(</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">q</span><span class="op">]</span>, </span>
<span>          ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1.4</span><span class="op">)</span>, yaxt <span class="op">=</span> <span class="st">'n'</span>, type <span class="op">=</span> <span class="st">"l"</span>, ylab <span class="op">=</span> <span class="st">"Transition probability"</span>,</span>
<span>          xlab <span class="op">=</span> <span class="st">"Iteration"</span>, main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"Patient"</span>, <span class="va">Look_lab</span><span class="op">[</span><span class="va">q</span><span class="op">]</span>, <span class="st">"in state"</span>, <span class="va">i</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"#8da0cb"</span><span class="op">)</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/axis.html" class="external-link">axis</a></span><span class="op">(</span><span class="fl">2</span>, at <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>, <span class="fl">.2</span><span class="op">)</span>, las <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span>, y <span class="op">=</span> <span class="va">out_2st_b</span><span class="op">$</span><span class="va">emiss_prob_bar</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">[</span>,<span class="op">(</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">q_emiss</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">q</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"#e78ac3"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">"topright"</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"#8da0cb"</span>, <span class="st">"#e78ac3"</span><span class="op">)</span>, lwd <span class="op">=</span> <span class="fl">2</span>, </span>
<span>           legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Starting value set 1"</span>, <span class="st">"Starting value set 2"</span><span class="op">)</span>, bty <span class="op">=</span> <span class="st">"n"</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p><img src="tutorial-mhmm_files/figure-html/showing%20model%20convergence%20II%20trace%20plots-1.png" width="691.2"></p>
<p>It can be observed that the parameter estimates converge to the same parameter space, and that the chains mix well. Also, there is no evidence of label switching.</p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>

</div>
</div>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-altman2007" class="csl-entry">
Altman, Rachel MacKay. 2007. <span>“Mixed Hidden <span>M</span>arkov Models: An Extension of the Hidden <span>M</span>arkov Model to the Longitudinal Data Setting.”</span> <em>Journal of the American Statistical Association</em> 102 (477): 201–10.
</div>
<div id="ref-burge1998" class="csl-entry">
Burge, Christopher B, and Samuel Karlin. 1998. <span>“Finding the Genes in Genomic DNA.”</span> <em>Current Opinion in Structural Biology</em> 8 (3): 346–54.
</div>
<div id="ref-cappe2005" class="csl-entry">
Cappé, E. AND Rydén, O. AND Moulines. 2005. <em>Inference in Hidden <span>M</span>arkov Models</em>. New York: Springer.
</div>
<div id="ref-ephraim2002" class="csl-entry">
Ephraim, Yariv, and Neri Merhav. 2002. <span>“Hidden <span>M</span>arkov Processes.”</span> <em>Information Theory, IEEE Transactions on</em> 48 (6): 1518–69.
</div>
<div id="ref-forney1973" class="csl-entry">
Forney Jr, G David. 1973. <span>“The <span>V</span>iterbi Algorithm.”</span> <em>Proceedings of the IEEE</em> 61 (3): 268–78.
</div>
<div id="ref-deHaan2017" class="csl-entry">
Haan-Rietdijk, S de, Peter Kuppens, Cindy S Bergeman, LB Sheeber, NB Allen, and EL Hamaker. 2017. <span>“On the Use of Mixed Markov Models for Intensive Longitudinal Data.”</span> <em>Multivariate Behavioral Research</em> 52 (6): 747–67.
</div>
<div id="ref-henderson1997" class="csl-entry">
Henderson, John, Steven Salzberg, and Kenneth H Fasman. 1997. <span>“Finding Genes in DNA with a Hidden Markov Model.”</span> <em>Journal of Computational Biology</em> 4 (2): 127–41.
</div>
<div id="ref-krogh1994" class="csl-entry">
Krogh, Anders, I Saira Mian, and David Haussler. 1994. <span>“A Hidden Markov Model That Finds Genes in e. Coli DNA.”</span> <em>Nucleic Acids Research</em> 22 (22): 4768–78.
</div>
<div id="ref-Rabiner1989" class="csl-entry">
Rabiner, Lawrence R. 1989. <span>“A Tutorial on Hidden <span>M</span>arkov Models and Selected Applications in Speech Recognition.”</span> <em>Proceedings of the IEEE</em> 77 (2): 257–86.
</div>
<div id="ref-rueda2013" class="csl-entry">
Rueda, Oscar M, Cristina Rueda, and Ramon Diaz-Uriarte. 2013. <span>“A <span>B</span>ayesian <span>HMM</span> with Random Effects and an Unknown Number of States for <span>DNA</span> Copy Number Analysis.”</span> <em>Journal of Statistical Computation and Simulation</em> 83 (1): 82–96.
</div>
<div id="ref-ryden2008" class="csl-entry">
Rydén, Tobias. 2008. <span>“<span>EM</span> Versus <span>M</span>arkov Chain <span>M</span>onte <span>C</span>arlo for Estimation of Hidden <span>M</span>arkov Models: A Computational Perspective.”</span> <em>Bayesian Analysis</em> 3 (4): 659–88.
</div>
<div id="ref-scott2002" class="csl-entry">
Scott, Steven L. 2002. <span>“Bayesian Methods for Hidden <span>M</span>arkov Models.”</span> <em>Journal of the American Statistical Association</em> 97 (457).
</div>
<div id="ref-shirley2010" class="csl-entry">
Shirley, Kenneth E, Dylan S Small, Kevin G Lynch, Stephen A Maisto, and David W Oslin. 2010. <span>“Hidden <span>M</span>arkov Models for Alcoholism Treatment Trial Data.”</span> <em>The Annals of Applied Statistics</em>, 366–95.
</div>
<div id="ref-viterbi1967" class="csl-entry">
Viterbi, Andrew J. 1967. <span>“Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm.”</span> <em>Information Theory, IEEE Transactions on</em> 13 (2): 260–69.
</div>
<div id="ref-woodland2002" class="csl-entry">
Woodland, Philip C, and Daniel Povey. 2002. <span>“Large Scale Discriminative Training of Hidden Markov Models for Speech Recognition.”</span> <em>Computer Speech &amp; Language</em> 16 (1): 25–47.
</div>
<div id="ref-zhang2014" class="csl-entry">
Zhang, Yue, and Kiros Berhane. 2014. <span>“Bayesian Mixed Hidden <span>M</span>arkov Models: A Multi-Level Approach to Modeling Categorical Outcomes with Differential Misclassification.”</span> <em>Statistics in Medicine</em> 33 (8): 1395–1408.
</div>
<div id="ref-zucchini2016" class="csl-entry">
Zucchini, Walter, Iain L MacDonald, and Roland Langrock. 2016. <em>Hidden <span>M</span>arkov Models for Time Series: An Introduction Using <span>R</span></em>. Boca Raton: CRC Press.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by <a href="xxx">Emmeke Aarts</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
